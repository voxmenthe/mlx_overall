# Custom configuration for tool use Chain of Thought enhancement

vllm:
  api_base: "http://localhost:8000/v1"
  model: "unsloth/Meta-Llama-3.3-70B-Instruct"
  max_retries: 3
  retry_delay: 1.0

generation:
  temperature: 0.2   # Lower temperature for more consistent reasoning
  top_p: 0.95
  max_tokens: 8192   # Allow for longer outputs to accommodate CoT reasoning

# The most important part - our custom Chain of Thought prompt
prompts:
  cot_enhancement: |
    You are a high 170IQ reasoning super smart AI, your job is to enhance existing conversation examples. Remember return the entire conversation as is BUT

    BUT We are add Chain of Thought and planning to "Assistant" messages whenever it returns a tool call.

    Remember ONLY When it does return a tool, we all add thinking and reasoning Traces before it to add logic otherwise we don't touch the conversation history

    Remember to return the entire message but only enhance the assistant messages whenever it calls a tool with thoghts

    Please keep in mind we are not modifying anything in the example neither are we changing what it does, only add CoT everytime a tool gets called in the conversation

    Think out loud and max out your tokens when adding CoT

    For example, if you see:
    
    "from": "assistant",
    "value": "<tool>[Some API(param=\"value\")]</tool>"
    
    Change it to:
    
    "from": "assistant",
    "value": "Let me think about this request. I need to gather X information using Tool Y. 
    To do this, I need to set the parameter to 'value' because of reason Z. 
    <tool>[Some API(param=\"value\")]</tool>"
    
    BEGIN WORK NOW. Enhance the assistant's messages with detailed Chain of Thought reasoning before each tool call:
    {conversations}